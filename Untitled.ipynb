{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9853fdce",
   "metadata": {},
   "source": [
    "### IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd7ff258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474f490d",
   "metadata": {},
   "source": [
    "### Adding the filename and filesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a162666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'edmonton_canada.mp4'\n",
    "file_size = (1920,1080) # Assumes 1920x1080 mp4\n",
    "RESIZED_DIMENSIONS = (300, 300) # Dimensions that SSD was trained on. \n",
    "IMG_NORM_RATIO = 0.007843 # In grayscale a pixel can range between 0 and 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ddcd46",
   "metadata": {},
   "source": [
    "### Loading the pre-trained neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2a4b206",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.dnn.readNetFromCaffe('MobileNetSSD_deploy.prototxt.txt', \n",
    "        'MobileNetSSD_deploy.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c96c3e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classLabels = []\n",
    "file_name = 'Labels.txt'\n",
    "with open(file_name,'rt') as fpt:\n",
    "    classLabels = fpt.read().rstrip('\\n').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7807889a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "print(classLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f65daa4",
   "metadata": {},
   "source": [
    "### Creating the bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf7c3dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_colors = np.random.uniform(255,0,size = (len(classLabels),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30391135",
   "metadata": {},
   "source": [
    "### Video setup and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a42fcde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture(filename)\n",
    "while video.isOpened():\n",
    "    success, frame = video.read()\n",
    "    if success:\n",
    "        #Capturing the frames height and width\n",
    "        (h,w) = frame.shape[:2]\n",
    "        # Create a blob. A blob is a group of connected pixels in a binary \n",
    "        # frame that share some common property (e.g. grayscale value)\n",
    "        # Preprocess the frame to prepare it for deep learning classification\n",
    "        frame_blob = cv2.dnn.blobFromImage(cv2.resize(frame, RESIZED_DIMENSIONS),\n",
    "                                          IMG_NORM_RATIO, RESIZED_DIMENSIONS, 127.5)\n",
    "        model.setInput(frame_blob) #Set the input for the neural network\n",
    "        model_output = model.forward() #Predict the objects in the image\n",
    "        \n",
    "        for i in np.arange(0,model_output.shape[2]):\n",
    "            confidence = model_output[0,0,i,2]\n",
    "    \n",
    "            #Confidence must be atleast 30%\n",
    "            if confidence > 0.30:\n",
    "                idx = int(model_output[0,0,i,1])\n",
    "\n",
    "                bounding_box = model_output[0,0,i,3:7] * np.array([w,h,w,h])\n",
    "\n",
    "                (startX, startY, endX, endY) = bounding_box.astype(\"int\")\n",
    "\n",
    "                label = \"{}: {:.2f}%\".format(classLabels[idx],confidence*100)\n",
    "                cv2.rectangle(frame, (startX, startY),(endX,endY),bbox_colors[idx%3],2)\n",
    "                y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "                cv2.putText(frame, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX,0.5,bbox_colors[idx],2)\n",
    "        frame = cv2.resize(frame,file_size,interpolation = cv2.INTER_NEAREST)\n",
    "    else:\n",
    "        break\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
